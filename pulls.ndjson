{"pull_number":"1184","title":"Feat: Select backend devices via arg","body":"The main goal of this PR is to improve user experience in multi-gpu setups, allowing to chose which model part gets sent to which device.\r\n\r\nCli changes: \r\n- Adds the `--main-backend-device [device_name]` argument to set the default backend\r\n- remove `--clip-on-cpu`, `--vae-on-cpu` and `--control-net-cpu` arguments \r\n- replace them respectively with the new `--clip_backend_device [device_name]`, `--vae-backend-device [device_name]`, `--control-net-backend-device [device_name]` arguments \r\n- add the `--diffusion_backend_device` (control the device used for the diffusion/flow models) and the `--tae-backend-device`\r\n- add `--upscaler-backend-device`, `--photomaker-backend-device`, and `--vision-backend-device`\r\n- add `--list-devices` argument to print the list of available ggml devices and exit.\r\n- add `--rpc` argument to connect to a compatible GGML rpc server\r\n\r\nC API changes (stable-diffusion.h):\r\n-  Change the content of the `sd_ctx_params_t` struct. \r\n- `void list_backends_to_buffer(char* buffer, size_t buffer_size)` to write the details of the available buffers to a null-terminated char array. Devices are separated by newline characters (`\\n`), and the name and description of the device are separated by `\\t` character.\r\n- `size_t backend_list_size()` to get the size of the buffer needed for void list_backends_to_buffer\r\n- `void add_rpc_device(const char* address);` connect to a ggml RPC backend ([from llama.cpp](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc))\r\n\r\nThe default device selection should now consistently prioritize discrete GPUs over iGPUs.  \r\n\r\nFor example if you want to run the text encoders on CPU, you'd need to use `--clip_backend_device CPU` instead of `--clip-on-cpu`\r\n\r\nTODO:\r\n  - Fix bug with `--lora-apply-mode immediately` when clip and diffsion models are running on different (non-cpu) backends.\r\n  - Clean up logs\r\n  \r\nImportant: to use RPC, you need to add `-DGGML_RPC=ON` to the build. Additionally it requires either sd.cpp to be built with `-DSD_USE_SYSTEM_GGML` flag (I haven't tested that one), or the RPC server to be built with `-DCMAKE_C_FLAGS=\"-DGGML_MAX_NAME=128\" -DCMAKE_CXX_FLAGS=\"-DGGML_MAX_NAME=128\"` ([default is 64](https://github.com/ggml-org/ggml/pull/682))\r\n  \r\n  Fixes #1116","pull_head_sha":"29e8399b8db2892c0445d5176f4418fa70bd7c17","loci_pr_branch":"loci/pr-1184-select-backend","short_merge_base":"e411520","loci_main_branch":"loci/main-e411520"}
